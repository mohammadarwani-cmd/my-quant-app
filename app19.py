import streamlit as st
import pandas as pd
import numpy as np
import akshare as ak
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from datetime import datetime, timedelta, timezone

# ==========================================
# 1. æŠ•è¡Œçº§é¡µé¢é…ç½® & CSSæ ·å¼
# ==========================================
st.set_page_config(
    page_title="AlphaTarget | æ ¸å¿ƒèµ„äº§è½®åŠ¨ç­–ç•¥ç»ˆç«¯",
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ³¨å…¥ä¸“ä¸šé‡‘èç»ˆç«¯é£æ ¼CSS
st.markdown("""
<style>
    /* å…¨å±€å­—ä½“ä¸èƒŒæ™¯ */
    .stApp {
        background-color: #f8f9fa;
        font-family: 'Roboto', 'Helvetica Neue', sans-serif;
    }
    
    /* å…³é”®æŒ‡æ ‡å¡ç‰‡ */
    .metric-card {
        background-color: #ffffff;
        border: 1px solid #e0e0e0;
        border-radius: 8px;
        padding: 15px;
        box-shadow: 0 1px 3px rgba(0,0,0,0.05);
        text-align: center;
        transition: transform 0.2s;
    }
    .metric-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .metric-label {
        color: #6c757d;
        font-size: 0.85rem;
        text-transform: uppercase;
        letter-spacing: 0.5px;
        margin-bottom: 5px;
    }
    .metric-value {
        color: #212529;
        font-size: 1.5rem;
        font-weight: 700;
    }
    .metric-sub {
        font-size: 0.8rem;
        color: #adb5bd;
    }
    
    /* ä¿¡å·æ¨ªå¹… */
    .signal-banner {
        padding: 20px;
        border-radius: 8px;
        margin-bottom: 20px;
        color: white;
        background: linear-gradient(90deg, #1e3c72 0%, #2a5298 100%);
        box-shadow: 0 4px 15px rgba(30, 60, 114, 0.2);
    }
    
    /* å¹´ä»½æ”¶ç›Šè¡¨æ ¼æ ·å¼ */
    .dataframe {
        font-size: 14px !important;
    }
</style>
""", unsafe_allow_html=True)

# é»˜è®¤æ ‡çš„æ± 
DEFAULT_CODES = ["518880", "588000", "513100", "510180"]

# é¢„ç½®ETFæ˜ å°„è¡¨
PRESET_ETFS = {
    "518880": "é»„é‡‘ETF (é¿é™©)",
    "588000": "ç§‘åˆ›50 (ç¡¬ç§‘æŠ€)",
    "513100": "çº³æŒ‡100 (æµ·å¤–)",
    "510180": "ä¸Šè¯180 (è“ç­¹)",
    "159915": "åˆ›ä¸šæ¿æŒ‡ (æˆé•¿)",
    "510300": "æ²ªæ·±300 (å¤§ç›˜)",
    "510500": "ä¸­è¯500 (ä¸­ç›˜)",
    "512890": "çº¢åˆ©ä½æ³¢ (é˜²å¾¡)",
    "513500": "æ ‡æ™®500 (ç¾è‚¡)",
    "512480": "åŠå¯¼ä½“ETF (è¡Œä¸š)",
    "512880": "è¯åˆ¸ETF (Beta)"
}

# ==========================================
# 2. æ•°æ®å±‚ (Data Layer)
# ==========================================

@st.cache_data(ttl=3600*12) 
def get_all_etf_list():
    try:
        df = ak.fund_etf_spot_em()
        df['display'] = df['ä»£ç '] + " | " + df['åç§°']
        return df
    except:
        return pd.DataFrame()

@st.cache_data(ttl=3600*4)
def download_market_data(codes_list, end_date_str):
    """
    æ•°æ®ä¸‹è½½æ ¸å¿ƒï¼šåªè´Ÿè´£ä¸‹è½½ï¼Œä¸è´Ÿè´£UIäº¤äº’å’Œæ—¶é—´åˆ¤æ–­ï¼Œç¡®ä¿Cacheç¨³å®š
    """
    start_str = '20150101' 
    # end_str ç°åœ¨ç”±å¤–éƒ¨ä¼ å…¥ï¼Œè¿™éå¸¸é‡è¦ï¼Œå› ä¸ºè¿™å†³å®šäº†Cache key
    
    price_dict = {}
    name_map = {}
    
    # è·å–åç§°æ˜ å°„
    etf_list = get_all_etf_list()
    
    for code in codes_list:
        name = code
        if code in PRESET_ETFS:
            name = PRESET_ETFS[code].split(" ")[0]
        elif not etf_list.empty:
            match = etf_list[etf_list['ä»£ç '] == code]
            if not match.empty:
                name = match.iloc[0]['åç§°']
        
        name_map[code] = name
        
        try:
            df = ak.fund_etf_hist_em(symbol=code, period="daily", start_date=start_str, end_date=end_date_str, adjust="qfq")
            if not df.empty:
                df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
                df.set_index('æ—¥æœŸ', inplace=True)
                price_dict[name] = df['æ”¶ç›˜'].astype(float)
        except Exception as e:
            continue

    if not price_dict:
        return None, None

    # å¯¹é½æ•°æ®
    data = pd.concat(price_dict, axis=1).sort_index().ffill()
    data.dropna(how='all', inplace=True)
    
    if len(data) < 20:
        return None, None
        
    return data, name_map

# ==========================================
# 3. ç­–ç•¥å†…æ ¸ (Strategy Core)
# ==========================================

def calculate_momentum(data, lookback, smooth):
    mom = data.pct_change(lookback)
    if smooth > 1:
        mom = mom.rolling(smooth).mean()
    return mom

def fast_backtest_vectorized(daily_ret, mom_df, threshold):
    """
    å‘é‡åŒ–å¿«é€Ÿå›æµ‹ (ä»…ç”¨äºå‚æ•°ä¼˜åŒ–çš„å‡€å€¼è®¡ç®—ï¼Œå‡è®¾ä¸€æ¬¡æ€§æŠ•å…¥)
    """
    signal_mom = mom_df.shift(1)
    
    n_days, n_assets = daily_ret.shape
    p_ret = daily_ret.values
    p_mom = signal_mom.values
    
    strategy_ret = np.zeros(n_days)
    curr_idx = -1 
    
    for i in range(n_days):
        row_mom = p_mom[i]
        if np.isnan(row_mom).all(): continue
            
        clean_mom = np.nan_to_num(row_mom, nan=-np.inf)
        best_idx = np.argmax(clean_mom)
        best_val = clean_mom[best_idx]
        
        if curr_idx == -1:
            if best_val > -np.inf: curr_idx = best_idx
        else:
            curr_val = clean_mom[curr_idx]
            if best_idx != curr_idx:
                if best_val > curr_val + threshold:
                    curr_idx = best_idx
        
        if curr_idx != -1:
            strategy_ret[i] = p_ret[i, curr_idx]
            
    equity_curve = (1 + strategy_ret).cumprod()
    total_ret = equity_curve[-1] - 1
    
    cummax = np.maximum.accumulate(equity_curve)
    drawdown = (equity_curve - cummax) / cummax
    max_dd = drawdown.min()
    
    return total_ret, max_dd, equity_curve

# ==========================================
# 4. åˆ†æå¸ˆå·¥å…·ç®± (Analyst Toolkit)
# ==========================================

def calculate_pro_metrics(equity_curve, days_count):
    """
    è®¡ç®—æŠ•è¡Œçº§ç­–ç•¥æŒ‡æ ‡
    """
    if len(equity_curve) < 2: return {}
    
    # æ—¥æ”¶ç›Šç‡
    daily_ret = pd.Series(equity_curve).pct_change().fillna(0)
    
    # 1. åŸºç¡€æ”¶ç›Š
    total_ret = equity_curve[-1] / equity_curve[0] - 1
    
    # 2. å¹´åŒ–æ”¶ç›Š
    if days_count == 0: days_count = len(equity_curve)
    ann_ret = (1 + total_ret) ** (252 / days_count) - 1
    
    # 3. å¹´åŒ–æ³¢åŠ¨ç‡
    ann_vol = daily_ret.std() * np.sqrt(252)
    
    # 4. å¤æ™®æ¯”ç‡
    rf = 0.03
    sharpe = (ann_ret - rf) / (ann_vol + 1e-9)
    
    # 5. æœ€å¤§å›æ’¤
    cummax = np.maximum.accumulate(equity_curve)
    drawdown = (equity_curve - cummax) / cummax
    max_dd = drawdown.min()
    
    # 6. å¡ç›æ¯”ç‡
    calmar = ann_ret / (abs(max_dd) + 1e-9)
    
    return {
        "Total Return": total_ret,
        "CAGR": ann_ret,
        "Volatility": ann_vol,
        "Max Drawdown": max_dd,
        "Sharpe Ratio": sharpe,
        "Calmar Ratio": calmar
    }

def optimize_parameters(data):
    """
    ç²¾ç¡®å‚æ•°ç½‘æ ¼æœç´¢å¼•æ“ (Exact Grid Search)
    Lookback: 20-30 (Step 1)
    Smooth: 1-5 (Step 1)
    Threshold: 0-0.012 (Step 0.001)
    """
    lookbacks = range(20, 31, 1) # 20 åˆ° 30
    smooths = range(1, 6, 1)     # 1 åˆ° 5
    
    # ä½¿ç”¨ np.arange ç”Ÿæˆæµ®ç‚¹æ•°åºåˆ—ï¼Œæ³¨æ„ç»ˆç‚¹ä¸åŒ…å«ï¼Œæ‰€ä»¥è®¾ä¸º 0.013
    thresholds = np.arange(0.0, 0.013, 0.001) 
    
    daily_ret = data.pct_change().fillna(0)
    results = []
    
    total_iters = len(lookbacks) * len(smooths) * len(thresholds)
    
    # è¿›åº¦æ˜¾ç¤º
    progress_text = "æ ¸å¿ƒå‚æ•°ç©ºé—´éå†ä¸­ (å…± {} ç»„ç»„åˆ)...".format(total_iters)
    my_bar = st.progress(0, text=progress_text)
    
    idx = 0
    
    for lb in lookbacks:
        for sm in smooths:
            mom = calculate_momentum(data, lb, sm)
            for th in thresholds:
                # ä¼˜åŒ–æ—¶ä½¿ç”¨å‘é‡åŒ–å›æµ‹ï¼Œé€Ÿåº¦æœ€å¿«
                ret, dd, _ = fast_backtest_vectorized(daily_ret, mom, th)
                # é˜²æ­¢é™¤é›¶
                score = ret / (abs(dd) + 0.01) 
                results.append([lb, sm, th, ret, dd, score])
                
                idx += 1
                if idx % 50 == 0:
                    my_bar.progress(min(idx / total_iters, 1.0), text=f"{progress_text} {idx}/{total_iters}")
                    
    my_bar.empty()
    df_res = pd.DataFrame(results, columns=['å‘¨æœŸ', 'å¹³æ»‘', 'é˜ˆå€¼', 'ç´¯è®¡æ”¶ç›Š', 'æœ€å¤§å›æ’¤', 'å¾—åˆ†'])
    return df_res

# ==========================================
# 5. ä¸»ç¨‹åº UI
# ==========================================

def main():
    if 'params' not in st.session_state:
        st.session_state.params = {'lookback': 20, 'smooth': 3, 'threshold': 0.005}

    # --- ä¾§è¾¹æ  ---
    with st.sidebar:
        st.title("ğŸ›ï¸ ç­–ç•¥æ§åˆ¶å°")
        
        # 1. èµ„äº§æ± 
        st.subheader("1. èµ„äº§æ± é…ç½®")
        all_etfs = get_all_etf_list()
        options = all_etfs['display'].tolist() if not all_etfs.empty else DEFAULT_CODES
        defaults = [o for o in options if o.split(" | ")[0] in DEFAULT_CODES] if not all_etfs.empty else DEFAULT_CODES
        selected_display = st.multiselect("æ ¸å¿ƒæ ‡çš„æ± ", options, default=defaults)
        selected_codes = [x.split(" | ")[0] for x in selected_display]
        
        st.divider()
        
        # 2. èµ„é‡‘ç®¡ç†å®éªŒå®¤
        st.subheader("2. èµ„é‡‘ç®¡ç†å®éªŒå®¤")
        
        # A. æ—¶é—´æ®µé€‰æ‹©
        date_mode = st.radio("å›æµ‹åŒºé—´", ["å…¨å†å² (2015è‡³ä»Š)", "è‡ªå®šä¹‰åŒºé—´"], index=0)
        start_date = datetime(2015, 1, 1)
        end_date = datetime.now()
        
        if date_mode == "è‡ªå®šä¹‰åŒºé—´":
            c1, c2 = st.columns(2)
            start_date = c1.date_input("å¼€å§‹æ—¥æœŸ", datetime(2019, 1, 1))
            end_date = c2.date_input("ç»“æŸæ—¥æœŸ", datetime.now())
            # è½¬æ¢ä¸ºdatetime
            start_date = datetime.combine(start_date, datetime.min.time())
            end_date = datetime.combine(end_date, datetime.min.time())

        # B. æŠ•èµ„æ¨¡å¼
        invest_mode = st.radio("æŠ•èµ„æ¨¡å¼", ["ä¸€æ¬¡æ€§æŠ•å…¥ (Lump Sum)", "å®šæœŸå®šé¢ (SIP)"], index=0)
        
        initial_capital = 100000.0
        sip_amount = 0.0
        sip_freq = "None"
        
        if invest_mode == "ä¸€æ¬¡æ€§æŠ•å…¥ (Lump Sum)":
            initial_capital = st.number_input("åˆå§‹æœ¬é‡‘", value=100000.0, step=10000.0)
        else:
            c1, c2 = st.columns(2)
            initial_capital = c1.number_input("åˆå§‹åº•ä»“", value=10000.0, step=1000.0, help="å¼€å§‹æ—¶æŠ•å…¥çš„ç¬¬ä¸€ç¬”èµ„é‡‘")
            sip_amount = c2.number_input("å®šæŠ•é‡‘é¢", value=2000.0, step=500.0)
            sip_freq = st.selectbox("å®šæŠ•é¢‘ç‡", ["æ¯æœˆ (Monthly)", "æ¯å‘¨ (Weekly)"], index=0)

        st.divider()
        
        # 3. ç­–ç•¥å‚æ•°
        st.subheader("3. ç­–ç•¥å†…æ ¸å‚æ•°")
        p_lookback = st.slider("åŠ¨é‡å‘¨æœŸ", 5, 60, st.session_state.params['lookback'])
        p_smooth = st.slider("å¹³æ»‘çª—å£", 1, 10, st.session_state.params['smooth'])
        p_threshold = st.number_input("æ¢ä»“é˜ˆå€¼", 0.0, 0.05, st.session_state.params['threshold'], step=0.001, format="%.3f")
        
        st.session_state.params.update({'lookback': p_lookback, 'smooth': p_smooth, 'threshold': p_threshold})

    # --- ä¸»ç•Œé¢ ---
    st.markdown("## ğŸš€ æ ¸å¿ƒèµ„äº§è½®åŠ¨ç­–ç•¥ç»ˆç«¯ (AlphaTarget Pro)")
    
    if not selected_codes:
        st.warning("è¯·åœ¨å·¦ä¾§é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ ‡çš„ã€‚")
        st.stop()
        
    # 1. æ•°æ®åŠ è½½
    # æ™ºèƒ½æ—¶é—´åˆ¤å®š (Smart Timing) - ç§»è‡³ Main å‡½æ•°ä»¥é¿å… Cache Error
    utc_now = datetime.now(timezone.utc)
    beijing_now = utc_now + timedelta(hours=8)
    
    if beijing_now.hour >= 15:
        # ä¸‹åˆ3ç‚¹åï¼Œå°è¯•è·å–ä»Šæ—¥æ•°æ®
        target_date = beijing_now
        status_msg = f"å½“å‰åŒ—äº¬æ—¶é—´ {beijing_now.strftime('%H:%M')} (å·²æ”¶ç›˜)ï¼Œè·å–æˆªè‡³ä»Šæ—¥æ•°æ®"
    else:
        # ä¸‹åˆ3ç‚¹å‰ï¼Œä»…è·å–åˆ°æ˜¨æ—¥
        target_date = beijing_now - timedelta(days=1)
        status_msg = f"å½“å‰åŒ—äº¬æ—¶é—´ {beijing_now.strftime('%H:%M')} (ç›˜ä¸­)ï¼Œè·å–æˆªè‡³æ˜¨æ—¥æ•°æ®"
    
    # æ„é€ æˆªæ­¢æ—¥æœŸå­—ç¬¦ä¸²ï¼Œè¿™ä¼šä½œä¸ºCache Keyçš„ä¸€éƒ¨åˆ†
    end_date_str = target_date.strftime('%Y%m%d')

    with st.spinner("æ­£åœ¨æ¥å…¥å¸‚åœºæ•°æ®ç»ˆç«¯ (Smart-Link)..."):
        # ä¼ å…¥ end_date_strï¼Œç¡®ä¿æ¯å¤©15ç‚¹åç¼“å­˜è‡ªåŠ¨æ›´æ–°
        raw_data, name_map = download_market_data(selected_codes, end_date_str)
        
    # UI åé¦ˆæ”¾åœ¨ Spinner ä¹‹å
    st.toast(status_msg, icon="ğŸ•’")
        
    if raw_data is None:
        st.error("æ•°æ®è·å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–ä»£ç æœ‰æ•ˆæ€§ã€‚")
        st.stop()

    # 2. ç­–ç•¥è®¡ç®— (å«å®šæŠ•é€»è¾‘)
    # å…ˆè®¡ç®—å…¨é‡åŠ¨é‡ï¼Œé˜²æ­¢åˆ‡ç‰‡å¯¼è‡´å¼€å¤´æ— æ•°æ®
    daily_ret_all = raw_data.pct_change().fillna(0)
    mom_all = calculate_momentum(raw_data, p_lookback, p_smooth)
    
    # æ—¶é—´åˆ‡ç‰‡ï¼šæ ¹æ®ç”¨æˆ·é€‰æ‹©æˆªå–å›æµ‹æ®µ
    mask = (raw_data.index >= start_date) & (raw_data.index <= end_date)
    # å¦‚æœç­›é€‰åä¸ºç©ºï¼Œæç¤º
    if not mask.any():
        st.error("é€‰å®šåŒºé—´å†…æ— æœ‰æ•ˆäº¤æ˜“æ•°æ®ï¼Œè¯·è°ƒæ•´æ—¥æœŸã€‚")
        st.stop()
        
    sliced_data = raw_data.loc[mask]
    sliced_mom = mom_all.loc[mask] 
    sliced_ret = daily_ret_all.loc[mask]
    
    # è¯¦ç»†é€æ—¥å›æµ‹å¾ªç¯ (æ”¯æŒå®šæŠ•)
    signal_mom = sliced_mom.shift(1) # T-1æ—¥çš„ä¿¡å·
    
    dates = sliced_ret.index
    holdings = []
    
    # èµ„é‡‘è´¦æˆ·
    cash = initial_capital
    share_val = 0.0
    total_assets_curve = []
    total_invested_curve = [] # è®°å½•æŠ•å…¥æœ¬é‡‘
    total_invested = initial_capital
    
    curr_hold = None # å½“å‰æŒæœ‰çš„èµ„äº§ä»£ç 
    
    # å®šæŠ•è¾…åŠ©
    last_sip_date = dates[0]
    
    for i, date in enumerate(dates):
        # --- 1. å®šæŠ•é€»è¾‘ ---
        if invest_mode == "å®šæœŸå®šé¢ (SIP)" and i > 0:
            is_sip_day = False
            if sip_freq.startswith("æ¯æœˆ"):
                if date.month != last_sip_date.month:
                    is_sip_day = True
            elif sip_freq.startswith("æ¯å‘¨"):
                if date.weekday() == 0 and last_sip_date.weekday() != 0: 
                    is_sip_day = True
            
            if is_sip_day:
                cash += sip_amount
                total_invested += sip_amount
                last_sip_date = date
        
        # --- 2. ä¿¡å·ä¸æ¢ä»“é€»è¾‘ ---
        row = signal_mom.loc[date]
        r_today = sliced_ret.loc[date]
        
        target = curr_hold
        
        # åªæœ‰å½“æœ‰æœ‰æ•ˆä¿¡å·æ—¶æ‰å°è¯•æ¢ä»“
        if not row.isna().all():
            best_asset = row.idxmax()
            best_score = row.max()
            
            if curr_hold is None:
                target = best_asset
            else:
                curr_score = row.get(curr_hold, -np.inf)
                if best_asset != curr_hold:
                    if best_score > curr_score + p_threshold:
                        target = best_asset
        
        # --- 3. ç»“ç®—å½“æ—¥æ”¶ç›Š ---
        day_return = 0.0
        if curr_hold and curr_hold in r_today:
             day_return = r_today[curr_hold]
        
        # æ›´æ–°èµ„äº§
        share_val = share_val * (1 + day_return)
        
        if target:
            # èµ„é‡‘å…¥åœº
            share_val += cash 
            cash = 0.0
        
        total_equity = share_val + cash
        
        total_assets_curve.append(total_equity)
        total_invested_curve.append(total_invested)
        holdings.append(target if target else "Cash")
        curr_hold = target

    # ç»“æœé›†æ•´ç†
    df_res = pd.DataFrame({
        'æ€»èµ„äº§': total_assets_curve,
        'æŠ•å…¥æœ¬é‡‘': total_invested_curve,
        'æŒä»“': holdings,
        # 'æ—¥æ”¶ç›Šç‡': sliced_ret.mean(axis=1) # ç§»é™¤ä¸å¿…è¦çš„å¹³å‡å€¼
    }, index=dates)
    
    # --- æ–°å¢åŠŸèƒ½ï¼šç”Ÿæˆ"å…¨å¸‚åœºè¡¨ç°"åˆ— ---
    # æ ¼å¼åŒ–æ‰€æœ‰æ ‡çš„å½“æ—¥æ¶¨è·Œå¹…ä¸ºå­—ç¬¦ä¸²: "æ ‡çš„A: +1.2% | æ ‡çš„B: -0.5%"
    
    def format_market_perf(row, n_map):
        items = []
        # æŒ‰æ¶¨è·Œå¹…æ’åº
        sorted_items = row.sort_values(ascending=False)
        for code, val in sorted_items.items():
            name = n_map.get(code, code)
            # ç®€åŒ–åç§°ï¼Œå»æ‰(xxx)
            short_name = name.split("(")[0]
            items.append(f"{short_name}: {val:+.2%}")
        return " | ".join(items)

    df_res['å…¨å¸‚åœºè¡¨ç° (Monitor)'] = sliced_ret.apply(lambda r: format_market_perf(r, name_map), axis=1)

    # é‡æ–°è®¡ç®—ç­–ç•¥æ—¥æ”¶ç›Šç‡ (åŸºäºå‡€å€¼)
    df_res['ç­–ç•¥æ—¥æ”¶ç›Š'] = df_res['æ€»èµ„äº§'].pct_change().fillna(0)
    
    # === å¼•å…¥å•ä½å‡€å€¼è®¡ç®— (Unit NAV) ===
    # å¿«é€Ÿè·å– NAV æ›²çº¿
    _, _, nav_series = fast_backtest_vectorized(sliced_ret, sliced_mom, p_threshold)
    df_res['ç­–ç•¥å‡€å€¼'] = nav_series
    
    # 3. ä»Šæ—¥ä¿¡å·é¢æ¿
    latest_date = sliced_data.index[-1]
    last_hold = holdings[-1]
    # ä½¿ç”¨mom_allè·å–æœ€æ–°ï¼Œä¸”åªè·å–æœ‰æ•°æ®çš„åˆ—
    latest_mom = mom_all.iloc[-1].dropna().sort_values(ascending=False)
    
    col_sig1, col_sig2 = st.columns([2, 1])
    with col_sig1:
        st.markdown(f"""
        <div class="signal-banner">
            <h3 style="margin:0">ğŸ“Œ å½“å‰æŒä»“å»ºè®®: {name_map.get(last_hold, last_hold) if last_hold != 'Cash' else 'ç©ºä»“è§‚æœ›'}</h3>
            <div style="margin-top:10px; opacity:0.9">
                æ•°æ®æˆªæ­¢: {latest_date.strftime('%Y-%m-%d')} | ç­–ç•¥å‘¨æœŸ: {p_lookback}æ—¥ | é˜ˆå€¼: {p_threshold:.1%}
            </div>
        </div>
        """, unsafe_allow_html=True)
    with col_sig2:
        st.markdown("**ğŸ† å®æ—¶åŠ¨é‡æ’å**")
        if not latest_mom.empty:
            for i, (asset, score) in enumerate(latest_mom.head(3).items()):
                display_name = name_map.get(asset, asset)
                st.markdown(f"{i+1}. **{display_name}**: `{score:.2%}`")
        else:
            st.warning("æš‚æ— æœ‰æ•ˆåŠ¨é‡æ•°æ®")

    # 4. ä¼˜åŒ–å¼•æ“
    with st.expander("ğŸ› ï¸ ç­–ç•¥å‚æ•°ä¼˜åŒ–å¼•æ“ (Smart Optimizer)", expanded=False):
        st.info("ğŸ’¡ å·²å¯ç”¨é«˜ç²¾åº¦ç½‘æ ¼æœç´¢ï¼šLookback[20-30], Smooth[1-5], Threshold[0-0.012]")
        if st.button("è¿è¡Œå‚æ•°å¯»ä¼˜"):
            with st.spinner("AIæ­£åœ¨è¿›è¡Œé«˜ç²¾åº¦å‚æ•°éå†..."):
                opt_df = optimize_parameters(raw_data)
                best_ret = opt_df.loc[opt_df['ç´¯è®¡æ”¶ç›Š'].idxmax()]
                best_calmar = opt_df.loc[opt_df['å¾—åˆ†'].idxmax()]
                
                c1, c2 = st.columns(2)
                with c1:
                    st.code(f"ğŸ”¥ è¿›æ”»å‹ (Ret {best_ret['ç´¯è®¡æ”¶ç›Š']:.1%})\nLookback: {int(best_ret['å‘¨æœŸ'])}, Smooth: {int(best_ret['å¹³æ»‘'])}, Thres: {best_ret['é˜ˆå€¼']:.3f}")
                with c2:
                    st.code(f"ğŸ›¡ï¸ é˜²å¾¡å‹ (Score {best_ret['å¾—åˆ†']:.2f})\nLookback: {int(best_calmar['å‘¨æœŸ'])}, Smooth: {int(best_calmar['å¹³æ»‘'])}, Thres: {best_calmar['é˜ˆå€¼']:.3f}")

    st.divider()
    
    # 5. æ ¸å¿ƒæŠ¥è¡¨åŒº
    st.subheader("ğŸ“Š è´¦æˆ·æ·±åº¦åˆ†æ")
    
    # æ ¸å¿ƒæŒ‡æ ‡è®¡ç®—
    # è´¦æˆ·æ€»æ”¶ç›Šç‡
    account_ret = df_res['æ€»èµ„äº§'].iloc[-1] / df_res['æŠ•å…¥æœ¬é‡‘'].iloc[-1] - 1
    account_profit = df_res['æ€»èµ„äº§'].iloc[-1] - df_res['æŠ•å…¥æœ¬é‡‘'].iloc[-1]
    
    # ç­–ç•¥è¡¨ç°æŒ‡æ ‡ (åŸºäºå‡€å€¼)
    strat_metrics = calculate_pro_metrics(df_res['ç­–ç•¥å‡€å€¼'].values, len(df_res))
    
    m1, m2, m3, m4, m5 = st.columns(5)
    with m1: st.markdown(metric_html("è´¦æˆ·æ€»èµ„äº§", f"Â¥{df_res['æ€»èµ„äº§'].iloc[-1]:,.0f}", f"æœ¬é‡‘: Â¥{df_res['æŠ•å…¥æœ¬é‡‘'].iloc[-1]:,.0f}"), unsafe_allow_html=True)
    with m2: st.markdown(metric_html("è´¦æˆ·ç´¯è®¡æ”¶ç›Š", f"{account_ret:+.2%}", f"ç›ˆäº: Â¥{account_profit:+,.0f}", color="#d62728" if account_profit>0 else "green"), unsafe_allow_html=True)
    with m3: st.markdown(metric_html("ç­–ç•¥å¹´åŒ– (CAGR)", f"{strat_metrics.get('CAGR',0):.1%}", "Time Weighted"), unsafe_allow_html=True)
    with m4: st.markdown(metric_html("æœ€å¤§å›æ’¤", f"{strat_metrics.get('Max Drawdown',0):.1%}", "ç­–ç•¥é£é™©"), unsafe_allow_html=True)
    with m5: st.markdown(metric_html("å¤æ™®æ¯”ç‡", f"{strat_metrics.get('Sharpe Ratio',0):.2f}", "é£é™©è°ƒæ•´åæ”¶ç›Š"), unsafe_allow_html=True)

    # å›¾è¡¨åŒº
    tab_curve, tab_year, tab_daily, tab_dd = st.tabs(["ğŸ“ˆ èµ„äº§æ›²çº¿", "ğŸ“… å¹´åº¦å›æŠ¥è¡¨", "ğŸ“ æ¯æ—¥äº¤æ˜“æ—¥è®°", "ğŸ“‰ é£é™©åˆ†æ"])
    
    with tab_curve:
        fig = go.Figure()
        # è´¦æˆ·èµ„äº§
        fig.add_trace(go.Scatter(x=df_res.index, y=df_res['æ€»èµ„äº§'], name="è´¦æˆ·æ€»èµ„äº§", line=dict(color='#1e3c72', width=2)))
        # æŠ•å…¥æœ¬é‡‘çº¿
        fig.add_trace(go.Scatter(x=df_res.index, y=df_res['æŠ•å…¥æœ¬é‡‘'], name="æŠ•å…¥æœ¬é‡‘", line=dict(color='#adb5bd', dash='dash')))
        
        fig.update_layout(height=450, hovermode="x unified", title="è´¦æˆ·èµ„äº§å¢é•¿æ›²çº¿ (Asset Growth)")
        st.plotly_chart(fig, use_container_width=True)
        
    with tab_year:
        # è®¡ç®—åˆ†å¹´åº¦æ”¶ç›Š
        res_y = []
        years = df_res.index.year.unique()
        for y in years:
            d_sub = df_res[df_res.index.year == y]
            start_nav = d_sub['ç­–ç•¥å‡€å€¼'].iloc[0]
            end_nav = d_sub['ç­–ç•¥å‡€å€¼'].iloc[-1]
            y_ret = end_nav / start_nav - 1
            
            # è´¦æˆ·å½“å¹´ç›ˆäº
            start_asset = d_sub['æ€»èµ„äº§'].iloc[0]
            end_asset = d_sub['æ€»èµ„äº§'].iloc[-1]
            net_inflow = d_sub['æŠ•å…¥æœ¬é‡‘'].iloc[-1] - d_sub['æŠ•å…¥æœ¬é‡‘'].iloc[0]
            y_profit = end_asset - start_asset - net_inflow
            
            res_y.append({
                "å¹´ä»½": y,
                "ç­–ç•¥æ”¶ç›Šç‡": y_ret,
                "è´¦æˆ·å½“å¹´ç›ˆäº": y_profit
            })
            
        df_year = pd.DataFrame(res_y).set_index("å¹´ä»½")
        
        st.markdown("#### åˆ†å¹´åº¦è¡¨ç° (Yearly Performance)")
        st.dataframe(
            df_year.style.format({
                "ç­–ç•¥æ”¶ç›Šç‡": "{:+.2%}",
                "è´¦æˆ·å½“å¹´ç›ˆäº": "{:+,.0f}"
            }).background_gradient(subset=["ç­–ç•¥æ”¶ç›Šç‡"], cmap="RdYlGn", vmin=-0.3, vmax=0.3),
            use_container_width=True
        )
        
    with tab_daily:
        st.markdown("#### æ¯æ—¥äº¤æ˜“è¯¦ç»†è®°å½•")
        # æ ¼å¼åŒ–æ˜¾ç¤º
        show_df = df_res[['æ€»èµ„äº§', 'æŠ•å…¥æœ¬é‡‘', 'æŒä»“', 'å…¨å¸‚åœºè¡¨ç° (Monitor)']].copy()
        show_df['æŒä»“åç§°'] = show_df['æŒä»“'].map(lambda x: name_map.get(x, x))
        show_df = show_df.sort_index(ascending=False)
        st.dataframe(
            show_df.style.format({
                "æ€»èµ„äº§": "{:,.2f}",
                "æŠ•å…¥æœ¬é‡‘": "{:,.2f}"
            }), 
            use_container_width=True,
            height=400
        )

    with tab_dd:
        dd_series = (df_res['ç­–ç•¥å‡€å€¼'] - df_res['ç­–ç•¥å‡€å€¼'].cummax()) / df_res['ç­–ç•¥å‡€å€¼'].cummax()
        fig_dd = go.Figure()
        fig_dd.add_trace(go.Scatter(x=dd_series.index, y=dd_series, fill='tozeroy', line=dict(color='darkred', width=1), name="å›æ’¤"))
        fig_dd.update_layout(title="ç­–ç•¥å†å²å›æ’¤ (Drawdown)", yaxis_tickformat='.1%', height=400)
        st.plotly_chart(fig_dd, use_container_width=True)

def metric_html(label, value, sub="", color="black"):
    return f"""
    <div class="metric-card">
        <div class="metric-label">{label}</div>
        <div class="metric-value" style="color:{color}">{value}</div>
        <div class="metric-sub">{sub}</div>
    </div>
    """

if __name__ == "__main__":
    main()
